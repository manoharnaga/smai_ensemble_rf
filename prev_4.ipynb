{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# For Regression\n",
    "\n",
    "file_path = \"HousingData.csv\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Open the CSV file and read its contents\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    \n",
    "    # Skip the header row if it exists\n",
    "    header = next(reader, None)\n",
    "    \n",
    "    # Read the data row by row and append to the list\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "# data.pop(0)\n",
    "# print(data[0])\n",
    "\n",
    "dataset = np.array(data)\n",
    "print(dataset.shape)\n",
    "\n",
    "y = dataset[:, -1]  # Extract the last column\n",
    "X = dataset[:, :-1]  # Remove the last column\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        if X[i][j] == 'NA':\n",
    "            X[i][j] = 0\n",
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
      " 7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
      " 9.1400e+00]\n",
      "[-0.40178501 -0.46815955 -0.50849056 -0.26839132 -0.74026221  0.19427445\n",
      "  0.42930593  0.55715988 -0.8678825  -0.98732948 -0.30309415  0.44105193\n",
      " -0.41351877]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = StandardScaler()\n",
    "print(X[1])\n",
    "# Fit and transform the imputer on your data\n",
    "X = scaler1.fit_transform(X)\n",
    "X = scaler2.fit_transform(X)\n",
    "print(X[1])\n",
    "\n",
    "y = y.astype(float)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "X_train_r, X_temp, y_train_r, y_temp = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Further split the remaining data into validation and test sets\n",
    "X_valid_r, X_test_r, y_valid_r, y_test_r = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Test: 16.01\n"
     ]
    }
   ],
   "source": [
    "## training and testing accuracy of the model\n",
    "\n",
    "decisiontreeclassifier = DecisionTreeRegressor()\n",
    "decisiontreeclassifier.fit(X_train_r,y_train_r)\n",
    "\n",
    "y_pred = decisiontreeclassifier.predict(X_test_r)\n",
    "\n",
    "mse_DT = mean_squared_error(y_test_r, y_pred)\n",
    "print(f\"Mean Squared Error Test: {mse_DT:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Regressor class\n",
    "\n",
    "class RandomForestRegressor():\n",
    "    def __init__(self,n_estimators,sample_fraction,bootstrap,voting):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_fraction = sample_fraction\n",
    "        self.bootstrap = bootstrap\n",
    "        self.voting = voting\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.forest = []\n",
    "        num_samples = X.shape[0]\n",
    "        self.selected_features = []\n",
    "\n",
    "        if self.bootstrap:\n",
    "            max_num_of_estimators = int(1/self.sample_fraction)\n",
    "            if self.n_estimators > max_num_of_estimators:\n",
    "                self.n_estimators = max_num_of_estimators\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                sample_indices = np.random.choice(num_samples, size=int(self.sample_fraction * num_samples), replace=True)\n",
    "            else:\n",
    "                sample_indices = np.random.choice(num_samples, size=int(self.sample_fraction * num_samples), replace=False)\n",
    "\n",
    "            X_sampled = X[sample_indices]\n",
    "            y_sampled = y[sample_indices]\n",
    "\n",
    "            # Randomly select K features\n",
    "            selected_features = np.random.choice(X.shape[1], size=13, replace=False)\n",
    "            X_sampled = X_sampled[:,selected_features]\n",
    "            self.selected_features.append(selected_features)\n",
    "\n",
    "            model = DecisionTreeRegressor()\n",
    "            model.fit(X_sampled, y_sampled)\n",
    "            self.forest.append(model)\n",
    "    \n",
    "    def get_selected_features(self):\n",
    "        return [tree.tree_.feature for tree in self.forest]\n",
    "\n",
    "    def predict(self, X, X_val, y_val):\n",
    "        # predictions = np.array([tree.predict(X[:, selected_features]) for tree, selected_features in zip(self.forest, self.get_selected_features())])\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(self.n_estimators):\n",
    "            predictions.append(self.forest[i].predict(X[:,self.selected_features[i]]))\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "\n",
    "        # Finding confidence value for each model using X_val and y_val\n",
    "        y_preds_val = []\n",
    "        for i in range(self.n_estimators):\n",
    "            y_preds_val.append(self.forest[i].predict(X_val[:,self.selected_features[i]]))\n",
    "        y_preds_val = np.array(y_preds_val)\n",
    "        y_preds_val = np.reshape(y_preds_val,(len(self.forest),X_val.shape[0]))\n",
    "        mses = np.mean((y_preds_val - y_val)**2, axis=1)\n",
    "        self.confidence = 1 / mses\n",
    "        normalizer = np.sum(self.confidence)\n",
    "\n",
    "        if self.voting == 'hard':\n",
    "            predictions_final = np.round(predictions.mean(axis=0))\n",
    "        elif self.voting == 'soft':\n",
    "            predictions = np.reshape(predictions,(X.shape[0],len(self.forest)))\n",
    "            predictions_final = np.sum(predictions * self.confidence, axis=1) / normalizer\n",
    "\n",
    "        return predictions_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "n_estimators = [5,10,15,20]\n",
    "sampling_fraction = [0.05,0.10,0.15, 0.25, 0.5, 0.75, 1.0]\n",
    "bootstrap = [True,False]\n",
    "voting = ['hard','soft']\n",
    "\n",
    "mse_results = []\n",
    "\n",
    "for i in range(1):\n",
    "    for n_est in n_estimators:\n",
    "        for s_frac in sampling_fraction:\n",
    "            for bootstrp in bootstrap:\n",
    "                for votin_mech in voting:\n",
    "                    ensemble_model = RandomForestRegressor(n_est,s_frac,bootstrap,votin_mech)\n",
    "                    start_time = time.time()\n",
    "                    ensemble_model.fit(X_train_r,y_train_r)\n",
    "                    end_time = time.time()\n",
    "                    predictions = ensemble_model.predict(X_test_r,X_valid_r,y_valid_r)\n",
    "                    mse = np.mean((y_test_r-predictions)**2)\n",
    "                    mse_results.append({\n",
    "                        'Number of Estimators': n_est,\n",
    "                        'Sampling Fraction': s_frac,\n",
    "                        'Bootstrap': bootstrp,\n",
    "                        'Voting Mechanism': votin_mech,\n",
    "                        'MSE': mse,\n",
    "                        'Training Time':end_time - start_time\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three Best-Performing Models:\n",
      "1. MSE: 6.9731 - {'Number of Estimators': 5, 'Sampling Fraction': 0.25, 'Bootstrap': False, 'Voting Mechanism': 'hard', 'MSE': 6.9731372549019595, 'Training Time': 0.002171039581298828}\n",
      "2. MSE: 7.5627 - {'Number of Estimators': 10, 'Sampling Fraction': 1.0, 'Bootstrap': False, 'Voting Mechanism': 'soft', 'MSE': 7.562745098039212, 'Training Time': 0.0014896392822265625}\n",
      "3. MSE: 8.0673 - {'Number of Estimators': 5, 'Sampling Fraction': 0.5, 'Bootstrap': True, 'Voting Mechanism': 'hard', 'MSE': 8.067254901960785, 'Training Time': 0.0014524459838867188}\n"
     ]
    }
   ],
   "source": [
    "# Sort the results based on MSE and print the top three\n",
    "sorted_results = sorted(mse_results, key=lambda x: x['MSE'])\n",
    "top_three_results = sorted_results[:3]\n",
    "\n",
    "print(\"Top Three Best-Performing Models:\")\n",
    "for i, result in enumerate(top_three_results, start=1):\n",
    "    print(f\"{i}. MSE: {result['MSE']:.4f} - {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1143, 13)\n",
      "['7.4' '0.7' '0.0' '1.9' '0.076' '11.0' '34.0' '0.9978' '3.51' '0.56'\n",
      " '9.4' '5']\n",
      "(1143, 11)\n",
      "(1143, 1)\n",
      "==============\n",
      "Input:  [ 7.4     0.7     0.      1.9     0.076  11.     34.      0.9978  3.51\n",
      "  0.56    9.4   ]\n",
      "Output:  [5.]\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "# For Classification\n",
    "\n",
    "file_path = 'WineQT.csv'\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Open the CSV file and read its contents\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    \n",
    "    # Skip the header row if it exists\n",
    "    header = next(reader, None)\n",
    "    \n",
    "    # Read the data row by row and append to the list\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "dataset = np.array(data)\n",
    "print(dataset.shape)\n",
    "dataset = dataset[:,:-1]\n",
    "print(dataset[0])\n",
    "# print(dataset[0])\n",
    "\n",
    "X = dataset[:,:-1]\n",
    "y = dataset[:,-1]\n",
    "y = np.reshape(y,(1143,1))\n",
    "X = X.astype('float64')\n",
    "y = y.astype('float64')\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"==============\")\n",
    "print(\"Input: \",X[0])\n",
    "print(\"Output: \",y[0])\n",
    "print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y.shape[0]):\n",
    "    if (y[i] == 3 or y[i] == 4 or y[i] == 5):\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0.]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = np.unique(y)\n",
    "print(unique_labels)\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "\n",
    "# Fit and transform the labels\n",
    "one_hot_encoded_labels = label_binarizer.fit_transform(y)\n",
    "print(y[0])\n",
    "print(one_hot_encoded_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.8     0.88    0.      2.6     0.098  25.     67.      0.9968  3.2\n",
      "  0.68    9.8   ]\n",
      "[-0.29259344  1.94181282 -1.36502663  0.05006018  0.23424656  0.91591972\n",
      "  0.64347653  0.03616459 -0.70892755  0.1308811  -0.59360107]\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = StandardScaler()\n",
    "print(X[1])\n",
    "# Fit and transform the imputer on your data\n",
    "X= imputer.fit_transform(X)\n",
    "X = scaler1.fit_transform(X)\n",
    "X = scaler2.fit_transform(X)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Further split the remaining data into validation and test sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test: 0.75\n",
      "Accuracy Valid: 0.73\n",
      "(114, 2)\n"
     ]
    }
   ],
   "source": [
    "## training and testing accuracy of the model\n",
    "\n",
    "decisiontreeclassifier = DecisionTreeClassifier()\n",
    "decisiontreeclassifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = decisiontreeclassifier.predict(X_test)\n",
    "\n",
    "accuracy_DT = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Test: {accuracy_DT:.2f}\")\n",
    "\n",
    "y_pred = decisiontreeclassifier.predict(X_valid)\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(f\"Accuracy Valid: {accuracy:.2f}\")\n",
    "\n",
    "pred_prob = decisiontreeclassifier.predict_proba(X_valid)\n",
    "print(pred_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier class\n",
    "\n",
    "### Random Forest Regressor class\n",
    "\n",
    "class RandomForestClassifier():\n",
    "    def __init__(self,n_estimators,sample_fraction,bootstrap,voting):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_fraction = sample_fraction\n",
    "        self.bootstrap = bootstrap\n",
    "        self.voting = voting\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.forest = []\n",
    "        num_samples = X.shape[0]\n",
    "        self.selected_features = []\n",
    "\n",
    "        if self.bootstrap:\n",
    "            max_num_of_estimators = int(1/self.sample_fraction)\n",
    "            if self.n_estimators > max_num_of_estimators:\n",
    "                self.n_estimators = max_num_of_estimators\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                sample_indices = np.random.choice(num_samples, size=int(self.sample_fraction * num_samples), replace=True)\n",
    "            else:\n",
    "                sample_indices = np.random.choice(num_samples, size=int(self.sample_fraction * num_samples), replace=False)\n",
    "\n",
    "            X_sampled = X[sample_indices]\n",
    "            y_sampled = y[sample_indices]\n",
    "\n",
    "            # Randomly select K features\n",
    "            selected_features = np.random.choice(X.shape[1], size=11, replace=False)\n",
    "            X_sampled = X_sampled[:,selected_features]\n",
    "            self.selected_features.append(selected_features)\n",
    "\n",
    "            model = DecisionTreeClassifier()\n",
    "            model.fit(X_sampled, y_sampled)\n",
    "            self.forest.append(model)\n",
    "    \n",
    "    def get_selected_features(self):\n",
    "        return [tree.tree_.feature for tree in self.forest]\n",
    "    \n",
    "    def most_frequent_number(self,row):\n",
    "        return np.argmax(np.bincount(row))\n",
    "\n",
    "    def predict(self, X):\n",
    "        # predictions = np.array([tree.predict(X[:, selected_features]) for tree, selected_features in zip(self.forest, self.get_selected_features())])\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(self.n_estimators):\n",
    "            predictions.append(self.forest[i].predict(X[:,self.selected_features[i]]))\n",
    "        predictions = np.array(predictions)\n",
    "        predictions = predictions.astype(int)\n",
    "\n",
    "        if self.voting == 'hard':\n",
    "            predictions = np.reshape(predictions,(X.shape[0],len(self.forest)))\n",
    "            predictions_final = np.apply_along_axis(self.most_frequent_number, axis=1, arr=predictions)\n",
    "        elif self.voting == 'soft':\n",
    "            predictions_prob = []\n",
    "            for model in self.forest:\n",
    "                predictions_prob.append(model.predict_proba(X))\n",
    "            predictions_prob = np.array(predictions_prob)\n",
    "            predictions_prob = np.reshape(predictions_prob,(predictions_prob.shape[1],predictions_prob.shape[0],predictions_prob.shape[2]))\n",
    "            predictions = np.argmax(np.sum(predictions_prob,axis=1),axis=1)\n",
    "            return predictions\n",
    "\n",
    "        return predictions_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5,10,15,20]\n",
    "sampling_fraction = [0.05,0.10,0.15, 0.25, 0.5, 0.75, 1.0]\n",
    "bootstrap = [True,False]\n",
    "voting = ['hard','soft']\n",
    "\n",
    "acc_results = []\n",
    "\n",
    "for i in range(1):\n",
    "    for n_est in n_estimators:\n",
    "        for s_frac in sampling_fraction:\n",
    "            for bootstrp in bootstrap:\n",
    "                for votin_mech in voting:\n",
    "                    ensemble_model = RandomForestClassifier(n_est,s_frac,bootstrap,votin_mech)\n",
    "                    start_time = time.time()\n",
    "                    ensemble_model.fit(X_train,y_train)\n",
    "                    end_time = time.time()\n",
    "                    predictions = ensemble_model.predict(X_test)\n",
    "                    accuracy = accuracy_score(predictions,y_test)\n",
    "                    acc_results.append({\n",
    "                        'Number of Estimators': n_est,\n",
    "                        'Sampling Fraction': s_frac,\n",
    "                        'Bootstrap': bootstrp,\n",
    "                        'Voting Mechanism': votin_mech,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'Training time': end_time - start_time\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three Best-Performing Models:\n",
      "1. Accuracy: 0.8000 - {'Number of Estimators': 15, 'Sampling Fraction': 0.75, 'Bootstrap': False, 'Voting Mechanism': 'hard', 'Accuracy': 0.8, 'Training time': 0.002920389175415039}\n",
      "2. Accuracy: 0.7565 - {'Number of Estimators': 5, 'Sampling Fraction': 1.0, 'Bootstrap': False, 'Voting Mechanism': 'hard', 'Accuracy': 0.7565217391304347, 'Training time': 0.002920866012573242}\n",
      "3. Accuracy: 0.7217 - {'Number of Estimators': 10, 'Sampling Fraction': 1.0, 'Bootstrap': True, 'Voting Mechanism': 'hard', 'Accuracy': 0.7217391304347827, 'Training time': 0.003142833709716797}\n"
     ]
    }
   ],
   "source": [
    "# Sort the results based on MSE and print the top three\n",
    "sorted_results = sorted(acc_results, key=lambda x: x['Accuracy'],reverse=True)\n",
    "top_three_results = sorted_results[:3]\n",
    "\n",
    "print(\"Top Three Best-Performing Models:\")\n",
    "for i, result in enumerate(top_three_results, start=1):\n",
    "    print(f\"{i}. Accuracy: {result['Accuracy']:.4f} - {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
